{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16da4a84-65bc-42be-920e-b9d5e65d5486",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Tarefa 1 - Preparação do Dataset do Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d977f1a-61c6-4230-a1cd-f84c558fc71f",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: researchpy in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (0.3.6)\n",
      "Requirement already satisfied: scipy in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from researchpy) (1.13.1)\n",
      "Requirement already satisfied: numpy in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from researchpy) (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from researchpy) (2.2.2)\n",
      "Requirement already satisfied: statsmodels in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from researchpy) (0.14.4)\n",
      "Requirement already satisfied: patsy in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from researchpy) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from pandas->researchpy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from pandas->researchpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from pandas->researchpy) (2023.3)\n",
      "Requirement already satisfied: six in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from patsy->researchpy) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/dbarr0s/miniconda3/envs/DAA/lib/python3.12/site-packages (from statsmodels->researchpy) (24.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install researchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19f15cd8-3e03-4183-9744-e8c7d3303eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import sklearn as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c93341f-df75-462c-a4b6-29eb06c0e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, é o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "# Fixar a seed\n",
    "set_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efc12f5f-383f-4795-9983-6c272af52685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = pd.read_csv('./datasets/test_radiomics_hipocamp.csv')\n",
    "df_treino = pd.read_csv('./datasets/train_radiomics_hipocamp.csv')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "996fda9f-7587-4fd5-85ad-2e0ff842fdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2180)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e44ce09-d1b6-4e9d-aa87-289dd1afd3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 2181)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3b66a66-7452-401b-9bc1-1ca358a1ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 2180 entries, ID to Age\n",
      "dtypes: float64(2011), int64(150), object(19)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_teste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e896b624-f733-4161-a71d-d9452f7c9246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 2181 entries, ID to Transition\n",
      "dtypes: float64(2014), int64(147), object(20)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f3eed-dd4d-452d-98f3-ae56380ec00b",
   "metadata": {},
   "source": [
    "### Colunas de valor único\n",
    "\n",
    "Quando uma coluna contém o mesmo valor para todas as 305/100 entradas, esta não ajuda a distinguir entre as observações e não contribui para a construção de modelos preditivos, análises estatísticas, ou para entender padrões nos dados. Estas colunas podem ser consideradas redundantes e ocupam espaço desnecessário, o que também pode prejudicar a eficiência computacional ao aumentar o tempo de processamento. Com isto dito, em baixo pesquisamos todas essas colunas e eliminamos essas mesmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caaf0cd9-e6a6-4f15-9f87-2ac57f84a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy',\n",
      "       'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet',\n",
      "       'diagnostics_Versions_Python', 'diagnostics_Configuration_Settings',\n",
      "       'diagnostics_Configuration_EnabledImageTypes',\n",
      "       'diagnostics_Image-original_Dimensionality',\n",
      "       'diagnostics_Image-original_Spacing', 'diagnostics_Image-original_Size',\n",
      "       ...\n",
      "       'lbp-3D-m2_glszm_HighGrayLevelZoneEmphasis',\n",
      "       'lbp-3D-m2_glszm_LowGrayLevelZoneEmphasis',\n",
      "       'lbp-3D-m2_glszm_SizeZoneNonUniformity',\n",
      "       'lbp-3D-m2_glszm_SizeZoneNonUniformityNormalized',\n",
      "       'lbp-3D-m2_glszm_ZoneEntropy', 'lbp-3D-m2_ngtdm_Busyness',\n",
      "       'lbp-3D-m2_ngtdm_Coarseness', 'lbp-3D-m2_ngtdm_Complexity',\n",
      "       'lbp-3D-m2_ngtdm_Contrast', 'lbp-3D-m2_ngtdm_Strength'],\n",
      "      dtype='object', length=159)\n"
     ]
    }
   ],
   "source": [
    "constant_columns_teste = df_teste.columns[df_teste.nunique() == 1]\n",
    "print(constant_columns_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "640b165f-4594-47f9-99a3-44fbf0e4e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy',\n",
      "       'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet',\n",
      "       'diagnostics_Versions_Python', 'diagnostics_Configuration_Settings',\n",
      "       'diagnostics_Configuration_EnabledImageTypes',\n",
      "       'diagnostics_Image-original_Dimensionality',\n",
      "       'diagnostics_Image-original_Spacing', 'diagnostics_Image-original_Size',\n",
      "       ...\n",
      "       'lbp-3D-m2_glszm_HighGrayLevelZoneEmphasis',\n",
      "       'lbp-3D-m2_glszm_LowGrayLevelZoneEmphasis',\n",
      "       'lbp-3D-m2_glszm_SizeZoneNonUniformity',\n",
      "       'lbp-3D-m2_glszm_SizeZoneNonUniformityNormalized',\n",
      "       'lbp-3D-m2_glszm_ZoneEntropy', 'lbp-3D-m2_ngtdm_Busyness',\n",
      "       'lbp-3D-m2_ngtdm_Coarseness', 'lbp-3D-m2_ngtdm_Complexity',\n",
      "       'lbp-3D-m2_ngtdm_Contrast', 'lbp-3D-m2_ngtdm_Strength'],\n",
      "      dtype='object', length=159)\n"
     ]
    }
   ],
   "source": [
    "constant_columns_treino = df_treino.columns[df_treino.nunique() == 1]\n",
    "print(constant_columns_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfece79f-b3d2-4775-af53-7d4f6121d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_teste.drop(constant_columns_teste, axis=1)\n",
    "df_treino = df_treino.drop(constant_columns_treino, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "670267ed-7e95-4953-a3aa-69689ae70b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2021)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92a8fb4f-afb2-4418-9d95-9125691e344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 2022)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "018fa307-8479-4e39-b516-a115a3300031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 2021 entries, ID to Age\n",
      "dtypes: float64(1991), int64(22), object(8)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_teste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c711d7b5-a539-4a8b-a983-6989fe28285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 2022 entries, ID to Transition\n",
      "dtypes: float64(1994), int64(19), object(9)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82c54f-90a2-49b4-9e33-23f8d5b07c31",
   "metadata": {},
   "source": [
    "Depois de feita a eliminação das colunas redundantes, através dos comando ***shape***, verificamos que eliminamos ***159 colunas redundantes*** dos dois datasets.\n",
    "Com o comando ***info()***, verificamos para o dataset de teste, que dessas 159 colunas, 20 eram do tipo ***float64***, 128 eram do tipo ***int64*** e 11 eram do tipo ***object***.\n",
    "Com o comando ***info()***, verificamos para o dataset de treino, que dessas 159 colunas, 20 eram do tipo ***float64***, 128 eram do tipo ***int64*** e 11 eram do tipo ***object***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc522a01-d3c7-4a12-a864-3431e120a44e",
   "metadata": {},
   "source": [
    "### Análise de colunas do tipo ***object***\n",
    "\n",
    "Consideramos que as seguintes colunas a eliminar, não apresentam dados necessários para a previsão do atributo-objetivo, ***Transition:***\n",
    "- ***ID:*** porque representa apenas o ID das imagens obtidas.\n",
    "- ***Image e Mask:*** porque representa apenas a localização dos diferentes scans.\n",
    "- ***diagnostics_Image-original_Hash:*** porque representa um hash único para a imagem original, usado para verificar a integridade da imagem ou identificar duplicates, mas para análises quantitativas não é importante.\n",
    "- ***diagnostics_Mask-original_Hash:*** porque representa um hash único da mask original, utilizado para verificar a integridade da mask. Para análises quantitativas não é importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "638939eb-0ae6-4209-89a0-c68fed12df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                              Image  \\\n",
      "0  941_S_1194  /notebooks/disk2/DS2_FreeSurfer/ADNI_941_S_119...   \n",
      "1  036_S_0945  /notebooks/disk2/DS2_FreeSurfer/ADNI_036_S_094...   \n",
      "2  024_S_1171  /notebooks/disk2/DS2_FreeSurfer/ADNI_024_S_117...   \n",
      "3  035_S_0555  /notebooks/disk2/DS2_FreeSurfer/ADNI_035_S_055...   \n",
      "4  023_S_0081  /notebooks/disk2/DS2_FreeSurfer/ADNI_023_S_008...   \n",
      "\n",
      "                                                Mask  \\\n",
      "0  /notebooks/disk2/DS2_FreeSurfer/ADNI_941_S_119...   \n",
      "1  /notebooks/disk2/DS2_FreeSurfer/ADNI_036_S_094...   \n",
      "2  /notebooks/disk2/DS2_FreeSurfer/ADNI_024_S_117...   \n",
      "3  /notebooks/disk2/DS2_FreeSurfer/ADNI_035_S_055...   \n",
      "4  /notebooks/disk2/DS2_FreeSurfer/ADNI_023_S_008...   \n",
      "\n",
      "            diagnostics_Image-original_Hash  \\\n",
      "0  b4977b66eca7c1e38c03fb5193cca7ca01dd46ec   \n",
      "1  43850cb7e611c0438dbf2fee1f5800d548de621f   \n",
      "2  a27b647efa22a9d77a17a07e92657722a268552d   \n",
      "3  cbd443cf571aaa826bebc6cc9d4bf80f91afd938   \n",
      "4  41ce7f75ad8398dc3a8dfe4ea5debd4a84aac204   \n",
      "\n",
      "             diagnostics_Mask-original_Hash  \\\n",
      "0  b9cd2759de5fb379af13626ecc9b71f841df44c0   \n",
      "1  fbd8a283b4ad67264a096d5493c0e7663449f22a   \n",
      "2  3610f06f74981f83e23fa930825a6ba36faabcee   \n",
      "3  46f300320ae71541ff921d9e861af041bead5051   \n",
      "4  400a079bcf1ce0a02456918b5f8e2b17a148c7eb   \n",
      "\n",
      "  diagnostics_Mask-original_BoundingBox  \\\n",
      "0             (92, 123, 90, 42, 29, 76)   \n",
      "1             (79, 135, 90, 48, 16, 78)   \n",
      "2            (105, 112, 87, 45, 27, 80)   \n",
      "3             (88, 110, 88, 42, 30, 84)   \n",
      "4             (88, 145, 94, 45, 21, 71)   \n",
      "\n",
      "         diagnostics_Mask-original_CenterOfMassIndex  \\\n",
      "0  (114.35013341239252, 137.93240438778537, 127.3...   \n",
      "1  (105.5636763627475, 144.51344414568564, 127.57...   \n",
      "2  (128.06696716033483, 125.64842240824211, 125.5...   \n",
      "3  (110.5198398681267, 125.62310137760508, 130.65...   \n",
      "4  (112.50337605070966, 155.2838638555877, 129.34...   \n",
      "\n",
      "              diagnostics_Mask-original_CenterOfMass  \n",
      "0  (114.35013341239252, 137.93240438778537, 127.3...  \n",
      "1  (105.5636763627475, 144.51344414568564, 127.57...  \n",
      "2  (128.06696716033483, 125.64842240824211, 125.5...  \n",
      "3  (110.5198398681267, 125.62310137760508, 130.65...  \n",
      "4  (112.50337605070966, 155.2838638555877, 129.34...  \n",
      "           ID                                              Image  \\\n",
      "0  006_S_0681  /notebooks/disk2/DS2_FreeSurfer/ADNI_006_S_068...   \n",
      "1  941_S_1203  /notebooks/disk2/DS2_FreeSurfer/ADNI_941_S_120...   \n",
      "2  011_S_0003  /notebooks/disk2/DS2_FreeSurfer/ADNI_011_S_000...   \n",
      "3  057_S_0779  /notebooks/disk2/DS2_FreeSurfer/ADNI_057_S_077...   \n",
      "4  033_S_0920  /notebooks/disk2/DS2_FreeSurfer/ADNI_033_S_092...   \n",
      "\n",
      "                                                Mask  \\\n",
      "0  /notebooks/disk2/DS2_FreeSurfer/ADNI_006_S_068...   \n",
      "1  /notebooks/disk2/DS2_FreeSurfer/ADNI_941_S_120...   \n",
      "2  /notebooks/disk2/DS2_FreeSurfer/ADNI_011_S_000...   \n",
      "3  /notebooks/disk2/DS2_FreeSurfer/ADNI_057_S_077...   \n",
      "4  /notebooks/disk2/DS2_FreeSurfer/ADNI_033_S_092...   \n",
      "\n",
      "            diagnostics_Image-original_Hash  \\\n",
      "0  b5d774a32163a7ee822d42a07808a787f8687f56   \n",
      "1  397042d736bd790b7880b372b1749ff424f89cbe   \n",
      "2  84d679a88812c4aaf03a6d99f00c913b2f64506f   \n",
      "3  168f330d2ca3f097146e5d041f33b40672d230df   \n",
      "4  ea5f291ea107dfda5e5c725eae7c0555ced44ce4   \n",
      "\n",
      "             diagnostics_Mask-original_Hash  \\\n",
      "0  315bdd7a06bb73df17bfc1297398b4398e36e180   \n",
      "1  208a2b034b72592489315104ef526ca10d434f24   \n",
      "2  352220437f6381b051fd4173969519887b530df6   \n",
      "3  9f62584e8badeb5de90b797d0c86c5170465d90f   \n",
      "4  62ab23b0a4ea4c9e7574b1ea410bd90236fe1d6e   \n",
      "\n",
      "  diagnostics_Mask-original_BoundingBox  \\\n",
      "0            (103, 113, 93, 36, 30, 71)   \n",
      "1             (81, 127, 93, 47, 16, 73)   \n",
      "2             (77, 119, 89, 49, 30, 81)   \n",
      "3             (93, 102, 90, 41, 29, 78)   \n",
      "4             (87, 119, 91, 40, 27, 75)   \n",
      "\n",
      "         diagnostics_Mask-original_CenterOfMassIndex  \\\n",
      "0  (121.94230227976358, 129.27272727272728, 128.4...   \n",
      "1  (107.06170458927883, 135.28088443244633, 128.2...   \n",
      "2  (103.3640972118682, 135.28164604144922, 128.98...   \n",
      "3  (116.29827315541601, 118.67431469629271, 129.3...   \n",
      "4  (108.26561977948546, 132.05462746408287, 127.6...   \n",
      "\n",
      "              diagnostics_Mask-original_CenterOfMass Transition  \n",
      "0  (121.94230227976358, 129.27272727272728, 128.4...      CN-CN  \n",
      "1  (107.06170458927883, 135.28088443244633, 128.2...      CN-CN  \n",
      "2  (103.3640972118682, 135.28164604144922, 128.98...      AD-AD  \n",
      "3  (116.29827315541601, 118.67431469629271, 129.3...     CN-MCI  \n",
      "4  (108.26561977948546, 132.05462746408287, 127.6...      CN-CN  \n"
     ]
    }
   ],
   "source": [
    "object_columns_teste = df_teste.select_dtypes(include='object')\n",
    "print(object_columns_teste.head())\n",
    "\n",
    "object_columns_treino = df_treino.select_dtypes(include='object')\n",
    "print(object_columns_treino.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d65a7c64-7e13-47e5-a19f-74e6a582bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_teste.drop('ID', axis=1)\n",
    "df_teste = df_teste.drop('Image', axis=1)\n",
    "df_teste = df_teste.drop('Mask', axis=1)\n",
    "df_teste = df_teste.drop('diagnostics_Image-original_Hash', axis=1)\n",
    "df_teste = df_teste.drop('diagnostics_Mask-original_Hash', axis=1)\n",
    "df_teste = df_teste.drop('diagnostics_Mask-original_CenterOfMass', axis=1)\n",
    "\n",
    "df_treino = df_treino.drop('ID', axis=1)\n",
    "df_treino = df_treino.drop('Image', axis=1)\n",
    "df_treino = df_treino.drop('Mask', axis=1)\n",
    "df_treino = df_treino.drop('diagnostics_Image-original_Hash', axis=1)\n",
    "df_treino = df_treino.drop('diagnostics_Mask-original_Hash', axis=1)\n",
    "df_treino = df_treino.drop('diagnostics_Mask-original_CenterOfMass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26260df7-0293-4fef-b968-364f969eb629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2015)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58781ecd-7dd7-4801-98f0-6c44fa7ddefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 2015 entries, diagnostics_Image-original_Mean to Age\n",
      "dtypes: float64(1991), int64(22), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_teste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4223ee7d-6f10-428a-bf70-29f9d2e112af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 2016)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1aec0f4a-4212-4138-84c7-38b36588913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 2016 entries, diagnostics_Image-original_Mean to Transition\n",
      "dtypes: float64(1994), int64(19), object(3)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d7288-21a5-4759-9d60-f403b4826f4a",
   "metadata": {},
   "source": [
    "De seguida, vamos analisar as colunas restantes do tipo ***object***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e0c38c9-de59-4cc0-b5f9-94cfffd257d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  diagnostics_Mask-original_BoundingBox  \\\n",
      "0             (92, 123, 90, 42, 29, 76)   \n",
      "1             (79, 135, 90, 48, 16, 78)   \n",
      "2            (105, 112, 87, 45, 27, 80)   \n",
      "3             (88, 110, 88, 42, 30, 84)   \n",
      "4             (88, 145, 94, 45, 21, 71)   \n",
      "\n",
      "         diagnostics_Mask-original_CenterOfMassIndex  \n",
      "0  (114.35013341239252, 137.93240438778537, 127.3...  \n",
      "1  (105.5636763627475, 144.51344414568564, 127.57...  \n",
      "2  (128.06696716033483, 125.64842240824211, 125.5...  \n",
      "3  (110.5198398681267, 125.62310137760508, 130.65...  \n",
      "4  (112.50337605070966, 155.2838638555877, 129.34...  \n",
      "  diagnostics_Mask-original_BoundingBox  \\\n",
      "0            (103, 113, 93, 36, 30, 71)   \n",
      "1             (81, 127, 93, 47, 16, 73)   \n",
      "2             (77, 119, 89, 49, 30, 81)   \n",
      "3             (93, 102, 90, 41, 29, 78)   \n",
      "4             (87, 119, 91, 40, 27, 75)   \n",
      "\n",
      "         diagnostics_Mask-original_CenterOfMassIndex Transition  \n",
      "0  (121.94230227976358, 129.27272727272728, 128.4...      CN-CN  \n",
      "1  (107.06170458927883, 135.28088443244633, 128.2...      CN-CN  \n",
      "2  (103.3640972118682, 135.28164604144922, 128.98...      AD-AD  \n",
      "3  (116.29827315541601, 118.67431469629271, 129.3...     CN-MCI  \n",
      "4  (108.26561977948546, 132.05462746408287, 127.6...      CN-CN  \n"
     ]
    }
   ],
   "source": [
    "object_columns_teste = df_teste.select_dtypes(include='object')\n",
    "print(object_columns_teste.head())\n",
    "\n",
    "object_columns_treino = df_treino.select_dtypes(include='object')\n",
    "print(object_columns_treino.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2cd8159-1d6e-48a9-aab1-26d87bfeaf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não\n"
     ]
    }
   ],
   "source": [
    "# Separar os elementos dos tuplos em colunas individuais\n",
    "bbox_cols = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'bbox_x3', 'bbox_y3']\n",
    "com_cols = ['com_x', 'com_y', 'com_z']\n",
    "\n",
    "df_teste[bbox_cols] = pd.DataFrame(df_teste['diagnostics_Mask-original_BoundingBox'].apply(eval).tolist(), index=df_teste.index)\n",
    "df_teste[com_cols] = pd.DataFrame(df_teste['diagnostics_Mask-original_CenterOfMassIndex'].apply(eval).tolist(), index=df_teste.index)\n",
    "\n",
    "# Remover as colunas originais\n",
    "df_teste = df_teste.drop('diagnostics_Mask-original_BoundingBox', axis = 1)\n",
    "df_teste = df_teste.drop('diagnostics_Mask-original_CenterOfMassIndex', axis=1)\n",
    "\n",
    "# Explicação das colunas\n",
    "# diagnostics_Mask-original_BoundingBox: Contém as coordenadas dos vértices da caixa delimitadora (bounding box).\n",
    "# diagnostics_Mask-original_CenterOfMassIndex: Contém as coordenadas do centro de massa.\n",
    "\n",
    "# Verificar a existência de valores ausentes\n",
    "missing_values = df_teste.isnull().sum()\n",
    "\n",
    "if missing_values.any():\n",
    "    print('Sim')\n",
    "    \n",
    "    # Imprimir os nomes das colunas com valores ausentes\n",
    "    cols_with_missing_values = missing_values[missing_values > 0].index.tolist()\n",
    "    print(\"Colunas com valores ausentes:\", cols_with_missing_values)\n",
    "else:\n",
    "    print('Não')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e637e1f-c862-4454-a105-06d2efabeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bbox_x1  bbox_y1  bbox_x2  bbox_y2  bbox_x3  bbox_y3       com_x  \\\n",
      "0       92      123       90       42       29       76  114.350133   \n",
      "1       79      135       90       48       16       78  105.563676   \n",
      "2      105      112       87       45       27       80  128.066967   \n",
      "3       88      110       88       42       30       84  110.519840   \n",
      "4       88      145       94       45       21       71  112.503376   \n",
      "\n",
      "        com_y       com_z  \n",
      "0  137.932404  127.331456  \n",
      "1  144.513444  127.574921  \n",
      "2  125.648422  125.565615  \n",
      "3  125.623101  130.657365  \n",
      "4  155.283864  129.348767  \n"
     ]
    }
   ],
   "source": [
    "# Imprimir as primeiras linhas das colunas especificadas\n",
    "columns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'bbox_x3', 'bbox_y3', 'com_x', 'com_y', 'com_z']\n",
    "print(df_teste[columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d913e0c9-d4ce-4191-84ae-ebfa550fc351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2022)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d28192a-3738-4fe1-be5e-d362f61d04d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 2022 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float64(1994), int64(28)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_teste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b232f54e-2bb8-48f9-a8f9-fb0c508490b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não\n"
     ]
    }
   ],
   "source": [
    "# Separar os elementos dos tuplos em colunas individuais\n",
    "bbox_cols = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'bbox_x3', 'bbox_y3']\n",
    "com_cols = ['com_x', 'com_y', 'com_z']\n",
    "\n",
    "df_treino[bbox_cols] = pd.DataFrame(df_treino['diagnostics_Mask-original_BoundingBox'].apply(eval).tolist(), index=df_treino.index)\n",
    "df_treino[com_cols] = pd.DataFrame(df_treino['diagnostics_Mask-original_CenterOfMassIndex'].apply(eval).tolist(), index=df_treino.index)\n",
    "\n",
    "# Remover as colunas originais\n",
    "df_treino = df_treino.drop('diagnostics_Mask-original_BoundingBox', axis = 1)\n",
    "df_treino = df_treino.drop('diagnostics_Mask-original_CenterOfMassIndex', axis=1)\n",
    "\n",
    "# Explicação das colunas\n",
    "# diagnostics_Mask-original_BoundingBox: Contém as coordenadas dos vértices da caixa delimitadora (bounding box).\n",
    "# diagnostics_Mask-original_CenterOfMassIndex: Contém as coordenadas do centro de massa.\n",
    "\n",
    "# Verificar a existência de valores ausentes\n",
    "missing_values = df_treino.isnull().sum()\n",
    "\n",
    "if missing_values.any():\n",
    "    print('Sim')\n",
    "    \n",
    "    # Imprimir os nomes das colunas com valores ausentes\n",
    "    cols_with_missing_values = missing_values[missing_values > 0].index.tolist()\n",
    "    print(\"Colunas com valores ausentes:\", cols_with_missing_values)\n",
    "else:\n",
    "    print('Não')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca49bf78-3de3-4176-bb05-d128016feb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bbox_x1  bbox_y1  bbox_x2  bbox_y2  bbox_x3  bbox_y3       com_x  \\\n",
      "0      103      113       93       36       30       71  121.942302   \n",
      "1       81      127       93       47       16       73  107.061705   \n",
      "2       77      119       89       49       30       81  103.364097   \n",
      "3       93      102       90       41       29       78  116.298273   \n",
      "4       87      119       91       40       27       75  108.265620   \n",
      "\n",
      "        com_y       com_z  \n",
      "0  129.272727  128.404025  \n",
      "1  135.280884  128.274585  \n",
      "2  135.281646  128.986283  \n",
      "3  118.674315  129.309866  \n",
      "4  132.054627  127.672068  \n"
     ]
    }
   ],
   "source": [
    "# Imprimir as primeiras linhas das colunas especificadas\n",
    "columns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'bbox_x3', 'bbox_y3', 'com_x', 'com_y', 'com_z']\n",
    "print(df_treino[columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3cac868-73b3-4a98-b095-020b3b0597e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 2023)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3eb0ad43-fe66-4582-affc-b2f41b85fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 2023 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float64(1997), int64(25), object(1)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c4506-e1c8-43de-a432-e2dc8da6ad8e",
   "metadata": {},
   "source": [
    "Eliminamos as seguintes colunas, ***diagnostics_Mask-original_BoundingBox', diagnostics_Mask-original_CenterOfMassIndex***, e criamos novas com cada um dos elementos de coordenadas dos tuplos ***['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'bbox_x3', 'bbox_y3', 'com_x', 'com_y', 'com_z'].***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f137b621-6587-4e1e-a18f-601e3bdaa405",
   "metadata": {},
   "source": [
    "### Remover colunas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce16a075-bde8-4759-b1ee-07591d23337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ainda existem colunas duplicadas em df_treino:\n",
      "Número de colunas duplicadas em df_treino: 163\n",
      "Ainda existem colunas duplicadas em df_teste:\n",
      "Número de colunas duplicadas em df_teste: 168\n",
      "Número de colunas comuns entre df_treino e df_teste: 163\n"
     ]
    }
   ],
   "source": [
    "# Verificar se há colunas duplicadas em df_treino\n",
    "duplicated_columns_treino = df_treino.T.duplicated(keep=False)\n",
    "\n",
    "# Exibir resultado para df_treino\n",
    "if duplicated_columns_treino.any():\n",
    "    print(\"Ainda existem colunas duplicadas em df_treino:\")\n",
    "    duplicate_column_names_treino = df_treino.columns[duplicated_columns_treino]\n",
    "    print(f\"Número de colunas duplicadas em df_treino: {len(duplicate_column_names_treino)}\")\n",
    "else:\n",
    "    print(\"Não há mais colunas duplicadas em df_treino.\")\n",
    "\n",
    "# Verificar se há colunas duplicadas em df_teste\n",
    "duplicated_columns_teste = df_teste.T.duplicated(keep=False)\n",
    "\n",
    "# Exibir resultado para df_teste\n",
    "if duplicated_columns_teste.any():\n",
    "    print(\"Ainda existem colunas duplicadas em df_teste:\")\n",
    "    duplicate_column_names_teste = df_teste.columns[duplicated_columns_teste]\n",
    "    print(f\"Número de colunas duplicadas em df_teste: {len(duplicate_column_names_teste)}\")\n",
    "else:\n",
    "    print(\"Não há mais colunas duplicadas em df_teste.\")\n",
    "\n",
    "# Verificar colunas comuns entre os dois datasets\n",
    "common_columns = set(duplicate_column_names_treino).intersection(set(duplicate_column_names_teste))\n",
    "print(f\"Número de colunas comuns entre df_treino e df_teste: {len(common_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e738d24-0201-445f-9665-733124f41771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de colunas duplicadas comuns removidas: 224\n",
      "Dimensões do df_treino após remoção: (305, 1911)\n",
      "Dimensões do df_teste após remoção: (100, 1910)\n"
     ]
    }
   ],
   "source": [
    "def remove_common_duplicated_columns(df1, df2):\n",
    "    # Identificar colunas duplicadas em cada DataFrame\n",
    "    duplicated_columns_df1 = df1.T.duplicated(keep=False)\n",
    "    duplicated_columns_df2 = df2.T.duplicated(keep=False)\n",
    "    \n",
    "    # Obter nomes das colunas duplicadas\n",
    "    duplicate_names_df1 = df1.columns[duplicated_columns_df1]\n",
    "    duplicate_names_df2 = df2.columns[duplicated_columns_df2]\n",
    "    \n",
    "    # Identificar duplicatas comuns entre os dois DataFrames\n",
    "    common_duplicated_columns = set(duplicate_names_df1).intersection(set(duplicate_names_df2))\n",
    "    \n",
    "    # Preparar listas para remoção\n",
    "    columns_to_remove_df1 = []\n",
    "    columns_to_remove_df2 = []\n",
    "    \n",
    "    # Remover duplicadas de df1 (mantém a primeira ocorrência de cada grupo)\n",
    "    if duplicated_columns_df1.any():\n",
    "        duplicated_data_df1 = df1.loc[:, duplicated_columns_df1]\n",
    "        grouped_duplicates_df1 = duplicated_data_df1.T.groupby(list(duplicated_data_df1.T)).groups\n",
    "        \n",
    "        for _, columns in grouped_duplicates_df1.items():\n",
    "            columns_to_remove_df1.extend([col for col in columns[1:] if col in common_duplicated_columns])\n",
    "    \n",
    "    # Remover duplicadas de df2 (mantém a primeira ocorrência de cada grupo)\n",
    "    if duplicated_columns_df2.any():\n",
    "        duplicated_data_df2 = df2.loc[:, duplicated_columns_df2]\n",
    "        grouped_duplicates_df2 = duplicated_data_df2.T.groupby(list(duplicated_data_df2.T)).groups\n",
    "        \n",
    "        for _, columns in grouped_duplicates_df2.items():\n",
    "            columns_to_remove_df2.extend([col for col in columns[1:] if col in common_duplicated_columns])\n",
    "    \n",
    "    # Aplicar remoção de colunas\n",
    "    df1.drop(columns=columns_to_remove_df1, inplace=True)\n",
    "    df2.drop(columns=columns_to_remove_df2, inplace=True)\n",
    "    \n",
    "    # Total de colunas removidas\n",
    "    total_removed = len(columns_to_remove_df1) + len(columns_to_remove_df2)\n",
    "    \n",
    "    print(f\"Total de colunas duplicadas comuns removidas: {total_removed}\")\n",
    "    \n",
    "    return df1, df2, total_removed\n",
    "\n",
    "# Uso da função\n",
    "df_treino, df_teste, total_removed_columns = remove_common_duplicated_columns(df_treino, df_teste)\n",
    "\n",
    "# Verificação adicional\n",
    "print(f\"Dimensões do df_treino após remoção: {df_treino.shape}\")\n",
    "print(f\"Dimensões do df_teste após remoção: {df_teste.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551d0e9-b91a-4b94-b796-d8f81bfd1021",
   "metadata": {},
   "source": [
    "Em seguida, vamos tratar dos outliers do dataset de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d3327-335e-4558-acfb-f3921d26a8a0",
   "metadata": {},
   "source": [
    "### Converter de float64 e int64 para float32 e int32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd55099-81ce-4b03-a4a0-94321237a89e",
   "metadata": {},
   "source": [
    "Começamos por tratar das conversões dos ints e floats do dataset de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a407c01-0a95-438e-8335-5ea7cafc7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 1910 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float32(1889), int32(21)\n",
      "memory usage: 746.2 KB\n"
     ]
    }
   ],
   "source": [
    "float_features = df_teste.select_dtypes(include='float')\n",
    "int_features = df_teste.select_dtypes(include='int')\n",
    "\n",
    "df_teste[float_features.columns] = df_teste[float_features.columns].astype(np.float32)\n",
    "df_teste[int_features.columns] = df_teste[int_features.columns].astype(np.int32)\n",
    "df_teste.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d594500-db47-47ef-bb5c-ac592b4a7cc5",
   "metadata": {},
   "source": [
    "Em seguida, vamos tratar das conversões dos ints e floats do dataset de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82771473-cffa-4cf6-9c73-b6b417b02cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 1911 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float32(1892), int32(18), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "float_features = df_treino.select_dtypes(include='float')\n",
    "int_features = df_treino.select_dtypes(include='int')\n",
    "\n",
    "df_treino[float_features.columns] = df_treino[float_features.columns].astype(np.float32)\n",
    "df_treino[int_features.columns] = df_treino[int_features.columns].astype(np.int32)\n",
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a6063-808c-49ae-9834-fb450e000fdd",
   "metadata": {},
   "source": [
    "### Exportar os datasets resultantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d73e292f-dc31-4b8e-85f0-97339f0aa6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final de teste limpo exportado para data_mod_hippo/dataset_teste.csv\n"
     ]
    }
   ],
   "source": [
    "# Criar a pasta se ela não existir\n",
    "output_folder = 'data_mod_hippo'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Exportar o DataFrame para um arquivo CSV na pasta criada\n",
    "output_file = os.path.join(output_folder, 'dataset_teste.csv')\n",
    "df_teste.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset final de teste limpo exportado para {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36afe782-aa14-4561-ad75-6f3bee454688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final de treino limpo exportado para data_mod_hippo/dataset_treino.csv\n"
     ]
    }
   ],
   "source": [
    "# Criar a pasta se ela não existir\n",
    "output_folder = 'data_mod_hippo'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Exportar o DataFrame para um arquivo CSV na pasta criada\n",
    "output_file = os.path.join(output_folder, 'dataset_treino.csv')\n",
    "df_treino.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset final de treino limpo exportado para {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
