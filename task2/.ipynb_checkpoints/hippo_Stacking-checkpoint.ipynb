{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4191fa8b-b877-42ac-be8b-4c5af51a6670",
   "metadata": {},
   "source": [
    "# Tarefa 2 - Stacking Classifier para o Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1539f5ce-d791-4223-bb4a-7925d305a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "856e716b-9459-43f9-bb7e-98c7943ae7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, é o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "# Fixar a seed\n",
    "set_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b065b5-d10e-4969-806e-d842645710ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_treino = pd.read_csv('./data_mod_hippo/dataset_treino.csv', na_filter=False)\n",
    "data_teste = pd.read_csv('./data_mod_hippo/dataset_teste.csv', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c6de2fc-125d-4783-ae27-5479ded1e7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 1911 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float64(1892), int64(18), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_treino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f01514e-9ccd-42a9-8866-1831cda6943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 1910 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float64(1889), int64(21)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "data_teste.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6056f-3ae0-40bc-adf7-97e57dd943ca",
   "metadata": {},
   "source": [
    "## Conversão de dados do tipo 64 para 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81216ce3-b074-492b-8b35-c093f5516bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 1911 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float32(1892), int32(18), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "float_features = data_treino.select_dtypes(include='float')\n",
    "int_features = data_treino.select_dtypes(include='int')\n",
    "\n",
    "data_treino[float_features.columns] = data_treino[float_features.columns].astype(np.float32)\n",
    "data_treino[int_features.columns] = data_treino[int_features.columns].astype(np.int32)\n",
    "data_treino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e37e06a-5bdb-48d7-9021-167bba267d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 1910 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float32(1889), int32(21)\n",
      "memory usage: 746.2 KB\n"
     ]
    }
   ],
   "source": [
    "float_features = data_teste.select_dtypes(include='float')\n",
    "int_features = data_teste.select_dtypes(include='int')\n",
    "\n",
    "data_teste[float_features.columns] = data_teste[float_features.columns].astype(np.float32)\n",
    "data_teste[int_features.columns] = data_teste[int_features.columns].astype(np.int32)\n",
    "data_teste.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c7bb9-2aba-4fe3-8c71-a0804de7d04f",
   "metadata": {},
   "source": [
    "## Normalização de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "870ba699-b4cf-4a77-8da0-cf2d63540074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnostics_Image-original_Mean</th>\n",
       "      <th>diagnostics_Image-original_Maximum</th>\n",
       "      <th>diagnostics_Mask-original_VoxelNum</th>\n",
       "      <th>original_shape_Elongation</th>\n",
       "      <th>original_shape_Flatness</th>\n",
       "      <th>original_shape_LeastAxisLength</th>\n",
       "      <th>original_shape_MajorAxisLength</th>\n",
       "      <th>original_shape_Maximum2DDiameterColumn</th>\n",
       "      <th>original_shape_Maximum2DDiameterRow</th>\n",
       "      <th>original_shape_Maximum2DDiameterSlice</th>\n",
       "      <th>...</th>\n",
       "      <th>bbox_x1</th>\n",
       "      <th>bbox_y1</th>\n",
       "      <th>bbox_x2</th>\n",
       "      <th>bbox_y2</th>\n",
       "      <th>bbox_x3</th>\n",
       "      <th>bbox_y3</th>\n",
       "      <th>com_x</th>\n",
       "      <th>com_y</th>\n",
       "      <th>com_z</th>\n",
       "      <th>Transition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.468027</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.598392</td>\n",
       "      <td>0.555087</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.392720</td>\n",
       "      <td>0.289560</td>\n",
       "      <td>0.310620</td>\n",
       "      <td>0.254940</td>\n",
       "      <td>0.562431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.723281</td>\n",
       "      <td>0.308972</td>\n",
       "      <td>0.578513</td>\n",
       "      <td>CN-CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281221</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>0.713552</td>\n",
       "      <td>0.588970</td>\n",
       "      <td>0.397306</td>\n",
       "      <td>0.338081</td>\n",
       "      <td>0.311579</td>\n",
       "      <td>0.359443</td>\n",
       "      <td>0.335667</td>\n",
       "      <td>0.619620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.276666</td>\n",
       "      <td>0.419646</td>\n",
       "      <td>0.571849</td>\n",
       "      <td>CN-CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.764980</td>\n",
       "      <td>0.212598</td>\n",
       "      <td>0.530116</td>\n",
       "      <td>0.727218</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431089</td>\n",
       "      <td>0.622046</td>\n",
       "      <td>0.583960</td>\n",
       "      <td>0.932585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.165689</td>\n",
       "      <td>0.419660</td>\n",
       "      <td>0.608489</td>\n",
       "      <td>AD-AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.651078</td>\n",
       "      <td>0.338583</td>\n",
       "      <td>0.799452</td>\n",
       "      <td>0.547963</td>\n",
       "      <td>0.355153</td>\n",
       "      <td>0.372946</td>\n",
       "      <td>0.453707</td>\n",
       "      <td>0.555160</td>\n",
       "      <td>0.498358</td>\n",
       "      <td>0.760667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.553885</td>\n",
       "      <td>0.113744</td>\n",
       "      <td>0.625148</td>\n",
       "      <td>CN-MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.382225</td>\n",
       "      <td>0.173228</td>\n",
       "      <td>0.406742</td>\n",
       "      <td>0.504096</td>\n",
       "      <td>0.080905</td>\n",
       "      <td>0.078060</td>\n",
       "      <td>0.545945</td>\n",
       "      <td>0.447539</td>\n",
       "      <td>0.424594</td>\n",
       "      <td>0.566272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.312799</td>\n",
       "      <td>0.360217</td>\n",
       "      <td>0.540829</td>\n",
       "      <td>CN-CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1911 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnostics_Image-original_Mean  diagnostics_Image-original_Maximum  \\\n",
       "0                         0.468027                            0.393701   \n",
       "1                         0.281221                            0.488189   \n",
       "2                         0.764980                            0.212598   \n",
       "3                         0.651078                            0.338583   \n",
       "4                         0.382225                            0.173228   \n",
       "\n",
       "   diagnostics_Mask-original_VoxelNum  original_shape_Elongation  \\\n",
       "0                            0.598392                   0.555087   \n",
       "1                            0.713552                   0.588970   \n",
       "2                            0.530116                   0.727218   \n",
       "3                            0.799452                   0.547963   \n",
       "4                            0.406742                   0.504096   \n",
       "\n",
       "   original_shape_Flatness  original_shape_LeastAxisLength  \\\n",
       "0                 0.455539                        0.392720   \n",
       "1                 0.397306                        0.338081   \n",
       "2                 0.876712                        1.000000   \n",
       "3                 0.355153                        0.372946   \n",
       "4                 0.080905                        0.078060   \n",
       "\n",
       "   original_shape_MajorAxisLength  original_shape_Maximum2DDiameterColumn  \\\n",
       "0                        0.289560                                0.310620   \n",
       "1                        0.311579                                0.359443   \n",
       "2                        0.431089                                0.622046   \n",
       "3                        0.453707                                0.555160   \n",
       "4                        0.545945                                0.447539   \n",
       "\n",
       "   original_shape_Maximum2DDiameterRow  original_shape_Maximum2DDiameterSlice  \\\n",
       "0                             0.254940                               0.562431   \n",
       "1                             0.335667                               0.619620   \n",
       "2                             0.583960                               0.932585   \n",
       "3                             0.498358                               0.760667   \n",
       "4                             0.424594                               0.566272   \n",
       "\n",
       "   ...   bbox_x1   bbox_y1   bbox_x2   bbox_y2  bbox_x3   bbox_y3     com_x  \\\n",
       "0  ...  0.769231  0.269841  0.571429  0.263158     0.68  0.250000  0.723281   \n",
       "1  ...  0.205128  0.492063  0.571429  0.842105     0.12  0.333333  0.276666   \n",
       "2  ...  0.102564  0.365079  0.285714  0.947368     0.68  0.666667  0.165689   \n",
       "3  ...  0.512821  0.095238  0.357143  0.526316     0.64  0.541667  0.553885   \n",
       "4  ...  0.358974  0.365079  0.428571  0.473684     0.56  0.416667  0.312799   \n",
       "\n",
       "      com_y     com_z  Transition  \n",
       "0  0.308972  0.578513       CN-CN  \n",
       "1  0.419646  0.571849       CN-CN  \n",
       "2  0.419660  0.608489       AD-AD  \n",
       "3  0.113744  0.625148      CN-MCI  \n",
       "4  0.360217  0.540829       CN-CN  \n",
       "\n",
       "[5 rows x 1911 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data_treino_normalize = data_treino.copy()\n",
    "data_teste_normalize = data_teste.copy()\n",
    "\n",
    "X_scale = data_treino_normalize.drop(columns=['Transition'])\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0,1)).fit(X_scale)\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1)).fit(data_teste_normalize)\n",
    "X_scale = pd.DataFrame(scaler_X.transform(X_scale[X_scale.columns]), columns=X_scale.columns)\n",
    "data_teste_normalize = pd.DataFrame(scaler_y.transform(data_teste_normalize[data_teste_normalize.columns]), columns=data_teste_normalize.columns)\n",
    "\n",
    "data_treino_normalize = pd.concat([X_scale, data_treino_normalize['Transition']], axis=1)\n",
    "\n",
    "data_treino_normalize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4fd0ca-a20e-4f3d-a7c7-577d0c6b1346",
   "metadata": {},
   "source": [
    "## Conversão de dados do tipo 64 para 32 depois da normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85bf8bc6-38bf-43d0-a862-cc4270bc500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 1911 entries, diagnostics_Image-original_Mean to Transition\n",
      "dtypes: float32(1910), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "float_features = data_treino_normalize.select_dtypes(include='float')\n",
    "int_features = data_treino_normalize.select_dtypes(include='int')\n",
    "\n",
    "data_treino_normalize[float_features.columns] = data_treino_normalize[float_features.columns].astype(np.float32)\n",
    "data_treino_normalize[int_features.columns] = data_treino_normalize[int_features.columns].astype(np.int32)\n",
    "data_treino_normalize.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff16e791-fa16-4599-bb49-a9d13846d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 1910 entries, diagnostics_Image-original_Mean to com_z\n",
      "dtypes: float32(1910)\n",
      "memory usage: 746.2 KB\n"
     ]
    }
   ],
   "source": [
    "float_features = data_teste_normalize.select_dtypes(include='float')\n",
    "int_features = data_teste_normalize.select_dtypes(include='int')\n",
    "\n",
    "data_teste_normalize[float_features.columns] = data_teste_normalize[float_features.columns].astype(np.float32)\n",
    "data_teste_normalize[int_features.columns] = data_teste_normalize[int_features.columns].astype(np.int32)\n",
    "data_teste_normalize.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ded0b-a4f5-4750-9337-c61b76786fc0",
   "metadata": {},
   "source": [
    "## Split dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcdb80df-e182-421d-88dc-bd6de48bde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_treino = data_treino_normalize.drop(columns=['Transition'])\n",
    "y_treino = data_treino_normalize['Transition']\n",
    "\n",
    "X_teste = data_teste_normalize\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_treino, y_treino, test_size=0.2, random_state=2023, stratify = y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11df375-5ba0-4cf7-940a-abe7276d3499",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4fa05-af0e-4e60-8927-c0e5062dcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=2023)\n",
    "model.fit(X_treino, y_treino)\n",
    "\n",
    "### 1. Feature Importance baseado em Mean Decrease in Impurity (MDI)\n",
    "mdi_importances = model.feature_importances_\n",
    "\n",
    "plt.hist(mdi_importances, bins=6, range=(0, max(mdi_importances)), color='green', alpha=0.7)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Zoomed Distribution of Feature Importances (MDI)\")\n",
    "plt.show()\n",
    "\n",
    "# Identificar features com importância MDI menor ou igual ao limite\n",
    "mdi_threshold = 0\n",
    "features_mdi = [feature for feature, importance in zip(X_treino.columns, mdi_importances) if importance == mdi_threshold]\n",
    "print(f\"Features com importância MDI - {mdi_threshold}: {len(features_mdi)}\")\n",
    "\n",
    "### 2. Feature Importance baseado em Permutation Importance\n",
    "perm_importance = permutation_importance(model, X_treino, y_treino, n_repeats=5, random_state=2023, n_jobs = -1)\n",
    "perm_importances = perm_importance.importances_mean\n",
    "\n",
    "plt.hist(perm_importances, bins=6, range=(0, max(perm_importances)), color='orange', alpha=0.7)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Zoomed Distribution of Feature Importances (Permutation Importance)\")\n",
    "plt.show()\n",
    "\n",
    "# Identificar features com importância de Permutation menor ou igual ao limite\n",
    "perm_threshold = 0\n",
    "features_perm = [feature for feature, importance in zip(X_treino.columns, perm_importances) if importance == perm_threshold]\n",
    "print(f\"Features com importância Permutation - {perm_threshold}: {len(features_perm)}\")\n",
    "\n",
    "### 3. Feature Importance baseado em SHAP\n",
    "# Criar valores SHAP para o modelo\n",
    "explainer = shap.TreeExplainer(model, X_treino)\n",
    "shap_values = explainer(X_treino, check_additivity=False)\n",
    "\n",
    "# Calcular a média dos valores absolutos de SHAP para cada feature\n",
    "shap_importances = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "# Garantir que shap_importances seja uma lista ou array unidimensional\n",
    "shap_importances = np.array(shap_importances).flatten()\n",
    "\n",
    "plt.hist(shap_importances, bins=6, range=(0, max(shap_importances)), color='cyan', alpha=0.7)\n",
    "plt.xlabel(\"SHAP Importance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Zoomed Distribution of Feature Importances (SHAP)\")\n",
    "plt.show()\n",
    "\n",
    "# Identificar features com importância SHAP menor ou igual ao limite\n",
    "shap_threshold = 0\n",
    "features_shap = [feature for feature, importance in zip(X_treino.columns, shap_importances) if importance == shap_threshold]\n",
    "print(f\"Features com importância SHAP - {shap_threshold}: {len(features_shap)}\")\n",
    "\n",
    "### 4. Combinação de todas as abordagenspermutat\n",
    "features_to_drop = list(\n",
    "    set(features_mdi).intersection(set(features_perm)).intersection(set(features_shap))\n",
    ")\n",
    "print(f\"Features a serem removidas (comuns a todas as abordagens): {len(features_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0e60d-e59f-421f-a0c3-1937b72156d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remover as features identificadas\n",
    "X_train = X_train.drop(columns=features_to_drop)\n",
    "X_test = X_test.drop(columns=features_to_drop)\n",
    "X_treino = X_treino.drop(columns=features_to_drop)\n",
    "X_teste = X_teste.drop(columns=features_to_drop)\n",
    "\n",
    "print(f\"Conjunto de treino reduzido: {X_treino.shape}\")\n",
    "print(f\"Conjunto de teste reduzido: {X_teste.shape}\")\n",
    "print(f\"Conjunto de treino reduzido: {X_train.shape}\")\n",
    "print(f\"Conjunto de teste reduzido: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a733d-d800-4641-875f-810b43cafadd",
   "metadata": {},
   "source": [
    "## Modelação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78588e31-c561-4c9f-ae88-9a0dd5f47504",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499bdf0-caf1-4a54-bad6-32d924d2cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "# Definir o modelo de Decision Tree e a grade de parâmetros\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, max_leaf_nodes=10, min_samples_leaf=20,min_samples_split=5, random_state=2023)\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_score = dt_model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (dt_score * 100))\n",
    "\n",
    "predictionDTC = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate F1-macro score\n",
    "f1_macro = f1_score(y_test, predictionDTC, average='macro')\n",
    "print(f\"F1 Macro: {f1_macro:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, predictionDTC))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predictionDTC)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557e35f-f159-4258-8d07-a5bfecf2eedc",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77498db-a607-426c-91a8-c5e5ac783d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "# Definir o modelo de Decision Tree e a grade de parâmetros\n",
    "svm_model = SVC(C=1, gamma=0.1, kernel='linear', random_state=2023)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "svm_score = svm_model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (svm_score * 100))\n",
    "\n",
    "predictionSVM = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate F1-macro score\n",
    "f1_macro = f1_score(y_test, predictionSVM, average='macro')\n",
    "print(f\"F1 Macro: {f1_macro:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, predictionSVM))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predictionSVM)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63337201-7806-4be1-a76e-d3ff2ea58fb7",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfd1d2-456a-4958-9439-d0ec78d24d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "mlp_model = MLPClassifier(activation='tanh', alpha=0.001, early_stopping=True, hidden_layer_sizes=(100, 50), max_iter=1000, random_state=2023, solver='lbfgs')\n",
    "\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "mlp_score = mlp_model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (mlp_score * 100))\n",
    "\n",
    "predictionMLP = mlp_model.predict(X_test)\n",
    "\n",
    "# Calculate F1-macro score\n",
    "f1_macro = f1_score(y_test, predictionMLP, average='macro')\n",
    "print(f\"F1 Macro: {f1_macro:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, predictionMLP))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predictionMLP)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917bdc09-3932-467f-8b68-679a44e8f334",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8db8b-39b9-4f4e-a857-b4baeb48911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "rfc_model = RandomForestClassifier(bootstrap=False, max_depth=10, min_samples_split=15, random_state=2023)\n",
    "\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "rfc_score = rfc_model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (rfc_score * 100))\n",
    "\n",
    "predictionRFC = rfc_model.predict(X_test)\n",
    "\n",
    "# Calculate F1-macro score\n",
    "f1_macro = f1_score(y_test, predictionRFC, average='macro')\n",
    "print(f\"F1 Macro: {f1_macro:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, predictionRFC))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predictionRFC)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e621265-d9ed-4114-9402-8804dbeaab56",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32458a-0259-4018-90de-0bff97aae5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "gbm_model = GradientBoostingClassifier(random_state=2023)\n",
    "\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "gbm_score = gbm_model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (gbm_score * 100))\n",
    "\n",
    "predictionGBM = gbm_model.predict(X_test)\n",
    "\n",
    "# Calculate F1-macro score\n",
    "f1_macro = f1_score(y_test, predictionGBM, average='macro')\n",
    "print(f\"F1 Macro: {f1_macro:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, predictionGBM))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predictionGBM)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051bce4f-0db7-4846-9fa5-e8c8712beeb7",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dbab8-7f0b-4877-9fc4-471b19bd06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [(\"gbm\", gbm_model), (\"svm\", svm_model), (\"mlp\", mlp_model)]    # 0.36761\n",
    "\n",
    "stc_model = StackingClassifier(estimators,final_estimator = rfc_model) \n",
    "\n",
    "stc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f7e48-53ed-4b3a-a947-b80f6931d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_score = stc_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (stc_score * 100))\n",
    "\n",
    "stc_predictions = stc_model.predict(X_test)\n",
    "\n",
    "# Calculate F1 Macro score\n",
    "stc_f1_macro = f1_score(y_test, stc_predictions, average='macro')\n",
    "print(f\"F1 Macro Score: {stc_f1_macro:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, stc_predictions))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, stc_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ecb2f-e2cf-4ebb-b1ac-3f10a285aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_model.fit(X_treino, y_treino)\n",
    "\n",
    "predictionSTC = stc_model.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a4475-477e-4761-b1fc-f0a76c9c1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_STC.csv', 'w') as results:\n",
    "    results.write('RowId,Result\\n')\n",
    "    i = 1\n",
    "    for p in predictionSTC:\n",
    "        results.write(f'{i},{p}\\n')\n",
    "        i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
